{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f0a7d8e-e88c-427f-8807-360dea5271be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-optimize in c:\\users\\user\\anaconda3\\lib\\site-packages (0.10.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.2.0)\n",
      "Requirement already satisfied: pyaml>=16.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-optimize) (24.9.0)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.2.2)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-optimize) (23.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikit-optimize) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a16ee294-8f4f-4b55-89ca-cfbaf60db320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, cross_val_score\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b487c308-731f-445f-8ce6-8148d2cb6926",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(r\"C:\\Users\\user\\Desktop\\ASU\\CIS 508\\508 HW 2\\Insurance Fraud - TRAIN-3000.csv\")\n",
    "test_data = pd.read_csv(r\"C:\\Users\\user\\Desktop\\ASU\\CIS 508\\508 HW 2\\Insurance Fraud -TEST-12900.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d6d3bf6-23fb-434a-b453-829aa47d4f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['FRAUDFOUND'] = train_data['FRAUDFOUND'].map({'Yes': 1, 'No': 0})\n",
    "test_data['FRAUDFOUND'] = test_data['FRAUDFOUND'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91d0a3bb-9e06-43a0-a000-425f57588404",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop('FRAUDFOUND', axis=1)\n",
    "y_train = train_data['FRAUDFOUND']\n",
    "X_test = test_data.drop('FRAUDFOUND', axis=1)\n",
    "y_test = test_data['FRAUDFOUND']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23950226-f569-4b8a-90b4-b89acae69ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train)\n",
    "X_test = pd.get_dummies(X_test)\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dff721f6-7e77-4320-af90-5ad95de01450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different parameter spaces and random seeds for each tuning method\n",
    "random_seeds = [42, 21, 84]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0dee738a-911d-435d-8228-da602619da0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest parameters\n",
    "rf_param_space_random = {\n",
    "    'n_estimators': randint(50, 300),\n",
    "    'max_depth': [10, 20, 30, 40, 50, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200, 250],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "rf_param_space_bayes = {\n",
    "    'n_estimators': (50, 300),\n",
    "    'max_depth': (10, 50),\n",
    "    'min_samples_split': (2, 10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fe7507a-8b25-47c0-8024-970e525054c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTree parameters\n",
    "dt_param_space_random = {\n",
    "    'max_depth': [10, 20, 30, 40, 50, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "dt_param_grid = {\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "dt_param_space_bayes = {\n",
    "    'max_depth': (10, 50),\n",
    "    'min_samples_split': (2, 10),\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74599a22-259d-4138-80ac-9c7e26981578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results\n",
    "results = {'Model': [], 'Tuning Method': [], 'Accuracy': [], 'Precision': [], 'Recall': [], 'F1 Score': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54334693-fd48-44d2-a4c5-531b186d026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to evaluate the model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5db58af1-a4a5-42a7-b4f6-d30c8b9a9177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Random Search\n"
     ]
    }
   ],
   "source": [
    "# Random Forest - Random Search\n",
    "print(\"Random Forest - Random Search\")\n",
    "rf_random = RandomForestClassifier(random_state=random_seeds[0])\n",
    "random_search_rf = RandomizedSearchCV(estimator=rf_random, param_distributions=rf_param_space_random, n_iter=10, cv=5, scoring='accuracy', random_state=random_seeds[0])\n",
    "random_search_rf.fit(X_train, y_train)\n",
    "accuracy, precision, recall, f1 = evaluate_model(random_search_rf.best_estimator_, X_test, y_test)\n",
    "results['Model'].append('Random Forest')\n",
    "results['Tuning Method'].append('Random Search')\n",
    "results['Accuracy'].append(accuracy)\n",
    "results['Precision'].append(precision)\n",
    "results['Recall'].append(recall)\n",
    "results['F1 Score'].append(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a830aea-d773-4ce7-ae4c-b371de3e8a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Random Search\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree - Random Search\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "print(\"Decision Tree - Random Search\")\n",
    "dt_random = DecisionTreeClassifier(random_state=random_seeds[0])\n",
    "random_search_dt = RandomizedSearchCV(estimator=dt_random, param_distributions=dt_param_space_random, n_iter=10, cv=5, scoring='accuracy', random_state=random_seeds[0])\n",
    "random_search_dt.fit(X_train, y_train)\n",
    "accuracy, precision, recall, f1 = evaluate_model(random_search_dt.best_estimator_, X_test, y_test)\n",
    "results['Model'].append('Decision Tree')\n",
    "results['Tuning Method'].append('Random Search')\n",
    "results['Accuracy'].append(accuracy)\n",
    "results['Precision'].append(precision)\n",
    "results['Recall'].append(recall)\n",
    "results['F1 Score'].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6beea83-ac9e-48ca-b91d-62ea7081da76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Grid Search\n"
     ]
    }
   ],
   "source": [
    "# Random Forest - Grid Search\n",
    "print(\"Random Forest - Grid Search\")\n",
    "rf_grid = RandomForestClassifier(random_state=random_seeds[1])\n",
    "grid_search_rf = GridSearchCV(estimator=rf_grid, param_grid=rf_param_grid, cv=5, scoring='accuracy')\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "accuracy, precision, recall, f1 = evaluate_model(grid_search_rf.best_estimator_, X_test, y_test)\n",
    "results['Model'].append('Random Forest')\n",
    "results['Tuning Method'].append('Grid Search')\n",
    "results['Accuracy'].append(accuracy)\n",
    "results['Precision'].append(precision)\n",
    "results['Recall'].append(recall)\n",
    "results['F1 Score'].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c173118c-5606-48db-96af-ab81a9fb9db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Grid Search\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree - Grid Search\n",
    "print(\"Decision Tree - Grid Search\")\n",
    "dt_grid = DecisionTreeClassifier(random_state=random_seeds[1])\n",
    "grid_search_dt = GridSearchCV(estimator=dt_grid, param_grid=dt_param_grid, cv=5, scoring='accuracy')\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "accuracy, precision, recall, f1 = evaluate_model(grid_search_dt.best_estimator_, X_test, y_test)\n",
    "results['Model'].append('Decision Tree')\n",
    "results['Tuning Method'].append('Grid Search')\n",
    "results['Accuracy'].append(accuracy)\n",
    "results['Precision'].append(precision)\n",
    "results['Recall'].append(recall)\n",
    "results['F1 Score'].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa1581f8-2be9-40df-a1de-503060b19c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Bayesian Search\n"
     ]
    }
   ],
   "source": [
    "# Random Forest - Bayesian Search\n",
    "print(\"Random Forest - Bayesian Search\")\n",
    "rf_bayes = RandomForestClassifier(random_state=random_seeds[2])\n",
    "bayes_search_rf = BayesSearchCV(estimator=rf_bayes, search_spaces=rf_param_space_bayes, cv=5, scoring='accuracy', n_iter=10, random_state=random_seeds[2])\n",
    "bayes_search_rf.fit(X_train, y_train)\n",
    "accuracy, precision, recall, f1 = evaluate_model(bayes_search_rf.best_estimator_, X_test, y_test)\n",
    "results['Model'].append('Random Forest')\n",
    "results['Tuning Method'].append('Bayesian Search')\n",
    "results['Accuracy'].append(accuracy)\n",
    "results['Precision'].append(precision)\n",
    "results['Recall'].append(recall)\n",
    "results['F1 Score'].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b0f9130-c9ce-4da9-8836-46983fc5e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Bayesian Search\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree - Bayesian Search\n",
    "print(\"Decision Tree - Bayesian Search\")\n",
    "dt_bayes = DecisionTreeClassifier(random_state=random_seeds[2])\n",
    "bayes_search_dt = BayesSearchCV(estimator=dt_bayes, search_spaces=dt_param_space_bayes, cv=5, scoring='accuracy', n_iter=10, random_state=random_seeds[2])\n",
    "bayes_search_dt.fit(X_train, y_train)\n",
    "accuracy, precision, recall, f1 = evaluate_model(bayes_search_dt.best_estimator_, X_test, y_test)\n",
    "results['Model'].append('Decision Tree')\n",
    "results['Tuning Method'].append('Bayesian Search')\n",
    "results['Accuracy'].append(accuracy)\n",
    "results['Precision'].append(precision)\n",
    "results['Recall'].append(recall)\n",
    "results['F1 Score'].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f31d40d-6177-4728-9816-d19c61cce627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Model    Tuning Method  Accuracy  Precision    Recall  F1 Score\n",
      "0  Random Forest    Random Search  0.951076   0.387584  0.463855  0.422303\n",
      "1  Decision Tree    Random Search  0.891856   0.217828  0.696787  0.331899\n",
      "2  Random Forest      Grid Search  0.963152   0.513580  0.835341  0.636086\n",
      "3  Decision Tree      Grid Search  0.920576   0.199317  0.351406  0.254360\n",
      "4  Random Forest  Bayesian Search  0.952469   0.406752  0.508032  0.451786\n",
      "5  Decision Tree  Bayesian Search  0.888450   0.227299  0.789157  0.352941\n"
     ]
    }
   ],
   "source": [
    "# Convert results to DataFrame and display\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "results_df.to_excel(\"model_comparison_results.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fba8483b-6f6d-4a1a-a4ef-37b953cfa316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model results (based on different metrics):\n",
      "Best Accuracy: Model            Random Forest\n",
      "Tuning Method      Grid Search\n",
      "Accuracy              0.963152\n",
      "Precision              0.51358\n",
      "Recall                0.835341\n",
      "F1 Score              0.636086\n",
      "Name: 2, dtype: object\n",
      "Best Precision: Model            Random Forest\n",
      "Tuning Method      Grid Search\n",
      "Accuracy              0.963152\n",
      "Precision              0.51358\n",
      "Recall                0.835341\n",
      "F1 Score              0.636086\n",
      "Name: 2, dtype: object\n",
      "Best Recall: Model            Random Forest\n",
      "Tuning Method      Grid Search\n",
      "Accuracy              0.963152\n",
      "Precision              0.51358\n",
      "Recall                0.835341\n",
      "F1 Score              0.636086\n",
      "Name: 2, dtype: object\n",
      "Best F1 Score: Model            Random Forest\n",
      "Tuning Method      Grid Search\n",
      "Accuracy              0.963152\n",
      "Precision              0.51358\n",
      "Recall                0.835341\n",
      "F1 Score              0.636086\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Identify and print the best model for each metric\n",
    "best_accuracy = results_df.loc[results_df['Accuracy'].idxmax()]\n",
    "best_precision = results_df.loc[results_df['Precision'].idxmax()]\n",
    "best_recall = results_df.loc[results_df['Recall'].idxmax()]\n",
    "best_f1_score = results_df.loc[results_df['F1 Score'].idxmax()]\n",
    "\n",
    "print(\"\\nBest model results (based on different metrics):\")\n",
    "print(\"Best Accuracy:\", best_accuracy)\n",
    "print(\"Best Precision:\", best_precision)\n",
    "print(\"Best Recall:\", best_recall)\n",
    "print(\"Best F1 Score:\", best_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d53e87eb-f6ae-48ce-9674-9910b53b7116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d011eeb-d41c-419f-9954-91f856de6ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0de4a575-e8f7-4786-bd1f-034287b14423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3321d7f5-96fd-4032-8ce3-de32c8df3de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8f57bd-d665-4419-a119-1dcbcf80bcac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
